{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(245,117,16), (117,245,16), (16,117,245)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    for num, prob in enumerate(res):\n",
    "        cv2.putText(output_frame, actions[num], (0, 85+num*40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return output_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(['accident', 'africa', 'again', 'all', 'basketball', 'because', 'before', 'bird', 'birthday', 'black', 'blue', 'book', 'bowling', 'boy', 'brown', 'but', 'can', 'candy', 'chair', 'change', 'cheat', 'check', 'city', 'clothes', 'cold', 'color', 'computer', 'cook', 'corn', 'cousin', 'cow', 'dance', 'dark', 'deaf', 'decide', 'doctor', 'dog', 'drink', 'eat', 'family', 'finish', 'forget', 'full', 'go', 'graduate', 'hair', 'headache', 'hearing', 'hello', 'help', 'language', 'last', 'later', 'laugh', 'like', 'man', 'medicine', 'meet', 'mother', 'no', 'now', 'orange', 'pink', 'pizza', 'play', 'secretary', 'study', 'table', 'teacher', 'Thank you', 'thin', 'trade', 'visit', 'wait', 'what', 'who', 'year', 'yes', 'you'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('80classes.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_47 (LSTM)               (None, 30, 512)           1308672   \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_48 (LSTM)               (None, 30, 512)           2099200   \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 30, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_49 (LSTM)               (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 79)                40527     \n",
      "=================================================================\n",
      "Total params: 6,072,911\n",
      "Trainable params: 6,072,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic # Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n",
    "    image.flags.writeable = False                  \n",
    "    results = model.process(image)                 \n",
    "    image.flags.writeable = True                   \n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) \n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS) # Draw right hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    #Draw left hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "    # Draw right hand connections  \n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([lh,rh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the model Demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Predictions:  ['mother' 'hello' 'drink' 'africa' 'brown']\n",
      "Top 5 Predictions:  ['Thank you' 'color' 'like' 'birthday' 'thin']\n",
      "Top 5 Predictions:  ['year' 'study' 'dance' 'table' 'medicine']\n",
      "Top 5 Predictions:  ['because' 'forget' 'black' 'later' 'eat']\n",
      "Top 5 Predictions:  ['you' 'yes' 'no' 'study' 'who']\n",
      "Top 5 Predictions:  ['headache' 'teacher' 'meet' 'basketball' 'cow']\n",
      "Top 5 Predictions:  ['computer' 'later' 'table' 'orange' 'no']\n"
     ]
    }
   ],
   "source": [
    "sequence = []\n",
    "sentence = []\n",
    "predictions = []\n",
    "threshold = 0.75\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set mediapipe model\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 720) #Camera window width\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)# Camera window height\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        # Read feed\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Make detections\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "        \n",
    "        # 2. Prediction logic\n",
    "        keypoints = extract_keypoints(results)\n",
    "        sequence.append(keypoints)\n",
    "        #print(len(sequence))\n",
    "        if len(sequence) == 30:\n",
    "            cv2.putText(image, 'Predecting', (200,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 4, cv2.LINE_AA)\n",
    "                   # Show to screen\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "            res = new_model.predict(np.expand_dims(sequence, axis=0))[0]  \n",
    "            out = np.argsort(res)\n",
    "            if res[np.argmax(res)] > threshold: #If one of the predicted words has probabiliy > than the threshold constant\n",
    "                out = np.argsort(-res)\n",
    "                predections = actions[out] #Get Prediction words string array\n",
    "                print(\"Top 5 Predictions: \" , predections[:5]) #Show first 5 predictions\n",
    "            cv2.waitKey(500) #Wait 500ms between each and every prediction\n",
    "            sequence = []\n",
    "        \n",
    "        # Show to screen\n",
    "        cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "        # Break gracefully\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfe51e1d02d2bc9eaaeb08688077fad9408935d49ad5f0b9dadabd25d94473ff"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
